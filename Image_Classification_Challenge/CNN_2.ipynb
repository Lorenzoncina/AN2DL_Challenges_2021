{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"from google.colab import drive\ndrive.mount('/gdrive')","metadata":{"id":"5-35gnQG8yoS","executionInfo":{"status":"ok","timestamp":1637158492507,"user_tz":-60,"elapsed":31768,"user":{"displayName":"Lorenzo Concina","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiLnKf1coP2pYmXw6Sl_cJmNswVos-lshTrqGYN5Q=s64","userId":"10813318479634581771"}},"outputId":"cb86f36d-f990-4206-85f3-55c5959547e3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%cd /gdrive/MyDrive/Homework_1_ImageClassification/","metadata":{"id":"8-rJySmy835Y","executionInfo":{"status":"ok","timestamp":1637158495160,"user_tz":-60,"elapsed":6,"user":{"displayName":"Lorenzo Concina","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiLnKf1coP2pYmXw6Sl_cJmNswVos-lshTrqGYN5Q=s64","userId":"10813318479634581771"}},"outputId":"3664b7a1-dcbd-4549-98ff-59a43a65f1e5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nimport numpy as np\nfrom PIL import Image\nimport matplotlib.pyplot as plt","metadata":{"id":"Kad8mvnp85ML"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#!unzip dataset.zip","metadata":{"id":"y9uCi_Gf9G9B"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset_dir = 'training'","metadata":{"id":"voCaRwS49Mol"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Plot example images from dataset\nlabels = ['Apple','Blueberry','Cherry','Corn','Grape','Orange','Peach','Pepper','Potato','Raspberry','Soybean','Squash','Strawberry','Tomato']\n\nnum_row = len(labels)//2\nnum_col = len(labels)//num_row\nfig, axes = plt.subplots(num_row, num_col, figsize=(2*num_row,15*num_col))\nfor i in range(len(labels)):\n  if i < len(labels):\n    class_imgs = next(os.walk('{}/{}/'.format(dataset_dir, labels[i])))[2]\n    class_img = class_imgs[0]\n    img = Image.open('{}/{}/{}'.format(dataset_dir, labels[i], class_img))\n    ax = axes[i//num_col, i%num_col]\n    ax.imshow(np.array(img))\n    ax.set_title('{}'.format(labels[i]))\nplt.tight_layout()\nplt.show()","metadata":{"id":"jffHrZfA9O3m","executionInfo":{"status":"ok","timestamp":1637145829839,"user_tz":-60,"elapsed":127364,"user":{"displayName":"Francesco","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhtGTREu-cpkASO6zdZ_aAuRgUjciFUqwE_icdLBQ=s64","userId":"01535802586943192589"}},"outputId":"6c2dae26-229f-4c1e-a2e8-24c93e960777"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Let the game begin","metadata":{"id":"Vw7zb8mT9Sk3"}},{"cell_type":"code","source":"import tensorflow as tf\ntfk = tf.keras\nprint(tf.__version__)","metadata":{"id":"rcl4rKRRlM50","executionInfo":{"status":"ok","timestamp":1637158510370,"user_tz":-60,"elapsed":2654,"user":{"displayName":"Lorenzo Concina","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiLnKf1coP2pYmXw6Sl_cJmNswVos-lshTrqGYN5Q=s64","userId":"10813318479634581771"}},"outputId":"9351f031-5ce2-41a2-eee3-86a7f6a1f9b3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Random seed for reproducibility\nseed = 42\n\n#random.seed(seed)\nos.environ['PYTHONHASHSEED'] = str(seed)\nnp.random.seed(seed)\ntf.random.set_seed(seed)\ntf.compat.v1.set_random_seed(seed)","metadata":{"id":"9OFHPLXcmAfb"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Train Validation Splitting**","metadata":{"id":"T2r--I7aLJGS"}},{"cell_type":"code","source":"image_generator_train = tfk.preprocessing.image.ImageDataGenerator(rescale = 1/255 , \n                                                             rotation_range = 30,\n                                                             height_shift_range = 50,\n                                                             width_shift_range= 50,\n                                                             zoom_range = 0.3,\n                                                             horizontal_flip = True,\n                                                             vertical_flip=True,\n                                                             fill_mode='reflect',\n                                                             validation_split=0.1)\n\ntrain_data = image_generator_train.flow_from_directory('training',\n                                                 target_size=(256,256),\n                                                 color_mode = 'rgb',\n                                                 classes=None,\n                                                 batch_size =64,\n                                                 shuffle = True,\n                                                 seed = seed,\n                                                 subset = \"training\")\n\n#For validation is necessary to create an ImageDataGenerator without data augmentation\nimage_generator_validation = tfk.preprocessing.image.ImageDataGenerator(rescale = 1/255 , \n                                                             validation_split=0.1)\n\n\nvalidation_data = image_generator_validation.flow_from_directory('training',\n                                                 target_size=(256,256),\n                                                 color_mode = 'rgb',\n                                                 classes=None,\n                                                 batch_size =64,\n                                                 shuffle = False,\n                                                 seed = seed,\n                                                 subset = \"validation\")\n","metadata":{"id":"d5ubIWQZwO95","executionInfo":{"status":"ok","timestamp":1637158550704,"user_tz":-60,"elapsed":35995,"user":{"displayName":"Lorenzo Concina","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiLnKf1coP2pYmXw6Sl_cJmNswVos-lshTrqGYN5Q=s64","userId":"10813318479634581771"}},"outputId":"5766fa55-4252-437b-c0c8-0f8fc635f5b0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"Assigned labels\")\nprint(train_data.class_indices)\nprint()\nprint(\"Target classes\")\nprint(train_data.classes)","metadata":{"id":"MZ_2AjUmB38-","executionInfo":{"status":"ok","timestamp":1637145891342,"user_tz":-60,"elapsed":323,"user":{"displayName":"Francesco","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhtGTREu-cpkASO6zdZ_aAuRgUjciFUqwE_icdLBQ=s64","userId":"01535802586943192589"}},"outputId":"e6fd9b02-60b7-40aa-f458-2a5a611398fa"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**CNN Model: build and fit**","metadata":{"id":"sQsg4qvq10Fv"}},{"cell_type":"code","source":"input_shape = (256,256,3)","metadata":{"id":"3GE9byvD3PWA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\"\"\"\nThis function creates the architecture of the our CNN\n\"\"\"\ndef create_model(input_shape):\n  model = tfk.Sequential()\n\n  #Convolutional block for feature extraction\n\n  #1\n  model.add(tfk.layers.Conv2D(\n      filters = 16,\n      kernel_size = (3,3),\n      strides = (1, 1),\n      activation = \"relu\",\n      padding = \"same\",\n      kernel_initializer = tfk.initializers.GlorotUniform(seed),\n      input_shape = input_shape\n  ))\n  model.add(tfk.layers.MaxPooling2D(pool_size=(2,2)))\n\n  model.add(tfk.layers.BatchNormalization())\n\n  #2\n  model.add(tfk.layers.Conv2D(\n      filters = 32,\n      kernel_size = (3,3),\n      strides = (1, 1),\n      activation = \"relu\",\n      padding = \"same\",\n      kernel_initializer = tfk.initializers.GlorotUniform(seed)\n  ))\n  model.add(tfk.layers.MaxPooling2D(pool_size=(2,2)))\n\n  model.add(tfk.layers.BatchNormalization())\n\n  #3\n  model.add(tfk.layers.Conv2D(\n      filters = 64,\n      kernel_size = (3,3),\n      strides = (1, 1),\n      activation = \"relu\",\n      padding = \"same\",\n      kernel_initializer = tfk.initializers.GlorotUniform(seed)\n  ))\n  model.add(tfk.layers.MaxPooling2D(pool_size=(2,2)))\n\n  model.add(tfk.layers.BatchNormalization())\n\n  #4\n  model.add(tfk.layers.Conv2D(\n      filters = 128,\n      kernel_size = (3,3),\n      activation = \"relu\",\n      padding = \"same\",\n      kernel_initializer = tfk.initializers.GlorotUniform(seed)\n  ))\n  model.add(tfk.layers.MaxPooling2D(pool_size=(2,2)))\n\n  model.add(tfk.layers.BatchNormalization())\n\n  #5\n  model.add(tfk.layers.Conv2D(\n      filters = 256,\n      kernel_size = (3,3),\n      activation = \"relu\",\n      padding = \"same\",\n      kernel_initializer = tfk.initializers.GlorotUniform(seed)\n  ))\n  model.add(tfk.layers.MaxPooling2D(pool_size=(2,2)))\n\n  model.add(tfk.layers.BatchNormalization())\n\n  model.add(tfk.layers.Flatten())\n\n  #Fully connected block for classification\n\n  model.add(tfk.layers.Dense(\n      units = 512,\n      activation = \"relu\",\n      kernel_initializer=tfk.initializers.GlorotUniform(seed)\n  ))\n\n  model.add(tfk.layers.Dropout(0.5,seed=seed))\n\n\n  #output layer\n  model.add(tfk.layers.Dense(\n      units = 14,\n      activation = \"softmax\",\n      kernel_initializer=tfk.initializers.GlorotUniform(seed)\n  ))\n\n  #compile model\n  model.compile(loss=tfk.losses.CategoricalCrossentropy() ,\n               optimizer = tfk.optimizers.Adam(),\n               metrics='accuracy' )\n  \n  return model\n","metadata":{"id":"WnhP9eyj1zdA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#callbacks (earlystopping)\ncallbacks = []\ncallbacks.append(tf.keras.callbacks.EarlyStopping(monitor ='val_loss', patience=5, restore_best_weights=True))","metadata":{"id":"nfdlTiHn-eml"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#build the model\ncnn_model = create_model(input_shape)\ncnn_model.summary()","metadata":{"id":"r25p8gBz8X8E"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#train the model\nhistory = cnn_model.fit(x = train_data,\n                        validation_data= validation_data,\n                        epochs = 100,\n                        callbacks = callbacks ).history","metadata":{"id":"JiETj5RJ88FA"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Loss and Accuracy Plot to monitor overfitting**","metadata":{"id":"rtOBUaZaMp0S"}},{"cell_type":"code","source":"#Error function plot\nimport matplotlib.pyplot as plt\nhistory_dict = history\nhistory_dict\nloss_values = history_dict['loss']\nvalidation_loss_values = history_dict['val_loss']\n\nepochs = range(1, len(loss_values) + 1)\n\nplt.plot(epochs, loss_values, 'bo', label = 'Training loss')\nplt.plot(epochs, validation_loss_values, label ='validation loss')\nplt.xlabel('epochs')\nplt.ylabel('error function ')\nplt.title('Training and validation loss')","metadata":{"id":"xpHM8ADbMPkV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#accuracy plot\naccuracy_values = history_dict['accuracy']\nvalidation_accuracy_values = history_dict['val_accuracy']\n\nplt.clf()\nplt.plot(epochs, accuracy_values, 'bo', label ='accurancy training')\nplt.plot(epochs, validation_accuracy_values)\nplt.xlabel('epochs')\nplt.ylabel('accurancy')\nplt.title('Training and validation accurancy')","metadata":{"id":"5ulBm8rLMzeT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#save the model \ncnn_model.save(\"CNN_fourth_model\")","metadata":{"id":"0SLA5nD8PKB-","executionInfo":{"status":"ok","timestamp":1637094205239,"user_tz":-60,"elapsed":2397,"user":{"displayName":"Francesco","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhtGTREu-cpkASO6zdZ_aAuRgUjciFUqwE_icdLBQ=s64","userId":"01535802586943192589"}},"outputId":"9c1325c3-ecf6-4569-f08d-e7a0c4effc62"},"execution_count":null,"outputs":[]}]}